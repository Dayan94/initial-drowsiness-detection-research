{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /Users/Dayan/anaconda3/lib/python3.8/site-packages (0.5.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Users/Dayan/anaconda3/lib/python3.8/site-packages (2.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVcf4sbRqGce"
   },
   "outputs": [],
   "source": [
    "#Required Packages\n",
    "import warnings  #  to warn programmers about changes in language or library features \n",
    "\n",
    "import dlib # for face detection and shape prediction\n",
    "import cv2 # OpenCV (Computer Vision) came with both cv and cv2. Now cv is a subclass inside cv2. cv2 is the latest \n",
    "from imutils import face_utils # to make basic image processing functions such as translation, rotation, resizing, \n",
    "                             # skeletonization, displaying Matplotlib images, sorting contours, detecting edges,etc\n",
    "    \n",
    "from scipy.spatial import distance # Distance metrics are contained in the scipy.spatial.distance submodule\n",
    "import math \n",
    "import numpy as np # support for large, multi-dimensional arrays and matrices, large collection of high-level mathematical functions to operate on these arrays\n",
    "import pandas as pd # for data manipulation and analysis, for manipulating numerical tables and time series\n",
    "\n",
    "\n",
    "                 # in anticipation of backwards incompatible changes coming with Python 3.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics # metrics module implements several loss, score, \n",
    "                            # and utility functions to measure classification performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score # 1. Compute Receiver operating characteristic (ROC).\n",
    "                                                # this implementation is restricted to the binary classification task\n",
    "                                                # 2. Compute Area Under the Receiver Operating Characteristic Curve \n",
    "                                                # (ROC AUC) from prediction scores.\n",
    "                                                # 3. F1 score, also known as balanced F-score or F-measure. \n",
    "                                                # F1 = 2 * (precision * recall) / (precision + recall)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # data visualization library based on matplotlib. \n",
    "                    # It provides a high-level interface for drawing attractive and informative statistical graphics\n",
    "from sklearn import preprocessing\n",
    "import pygame  # to play alarm.wav\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions for EAR, MAR, PUC, MOE, Average of 3 consecutive outputs of predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tqi058dZqGco"
   },
   "outputs": [],
   "source": [
    "#Feature Functions\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = distance.euclidean(mouth[2], mouth[10])\n",
    "    B = distance.euclidean(mouth[4], mouth[8])\n",
    "    C = distance.euclidean(mouth[0], mouth[6])\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "def pupil_circularity(eye):\n",
    "    A = distance.euclidean(eye[1], eye[4])\n",
    "    radius  = A/2.0\n",
    "    Area = math.pi * (radius ** 2)\n",
    "    p = 0\n",
    "    p += distance.euclidean(eye[0], eye[1])\n",
    "    p += distance.euclidean(eye[1], eye[2])\n",
    "    p += distance.euclidean(eye[2], eye[3])\n",
    "    p += distance.euclidean(eye[3], eye[4])\n",
    "    p += distance.euclidean(eye[4], eye[5])\n",
    "    p += distance.euclidean(eye[5], eye[0])\n",
    "    return 4 * math.pi * Area /(p**2)\n",
    "\n",
    "def mouth_over_eye(eye, mouth):\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    moe = mar/ear\n",
    "    return moe\n",
    "\n",
    "\n",
    "def average(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if i % 240 == 0  or i % 240 == 1  or i % 240 == 2 or i % 240 == 3 or i % 240 == 4  or i % 240 == 5 or i % 240 == 6  or i % 240 == 7  or i % 240 == 8: # skipping 1st - 9th frames from each video\n",
    "            continue\n",
    "        consecutive_10_predictions = y_pred[i-9:i+1]   \n",
    "        average = consecutive_10_predictions.mean() # each frame's 9th previous to ifself's labels' average will be used for new label \n",
    "        if average >= 0.5:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wluAHvusqGcu"
   },
   "outputs": [],
   "source": [
    "#Read in the Data file to Train Model\n",
    "df = pd.read_csv('Dataset/total_persons_main_info.csv',sep=',')\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "\n",
    "train_percentage = 20/25\n",
    "train_index = int(len(df)*train_percentage)\n",
    "test_index = len(df)-train_index\n",
    "\n",
    "df_train = df[:train_index]\n",
    "df_test = df[-test_index:]\n",
    "\n",
    "X_test = df_test.drop([\"Label\"],axis=1)\n",
    "y_test = df_test[\"Label\"]\n",
    "\n",
    "X_train = df_train.drop('Label',axis=1)\n",
    "y_train = df_train['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Logistic Regression - 1](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)\n",
    "## 2. [Logistic Regression - 2](https://towardsdatascience.com/logistic-regression-explained-and-implemented-in-python-880955306060)\n",
    "##  <img src=\"https://miro.medium.com/max/1400/1*RqXFpiNGwdiKBWyLJc_E7g.png\" style = \"width: 40vw\"> ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR = LogisticRegression()\n",
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [Naive Bayes](https://iq.opengenus.org/gaussian-naive-bayes/#:~:text=Gaussian%20Naive%20Bayes%20is%20a,distribution%20and%20supports%20continuous%20data.&text=Naive%20Bayes%20are%20a%20group,technique%2C%20but%20has%20high%20functionality) ##\n",
    "## <img src=\"https://iq.opengenus.org/content/images/2020/02/Screenshot_6.jpg\"> ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. [KNN](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0LK5DCcqGc2",
    "outputId": "8e6f7e52-2343-4138-fd97-95f09398295c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3_list = []\n",
    "f1_score3_list = []\n",
    "roc_3_list = []\n",
    "for i in range(1,30):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_train, y_train) \n",
    "    pred_KN = neigh.predict(X_test)\n",
    "    pred_KN = average(pred_KN)\n",
    "    y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "    acc3_list.append(accuracy_score(y_test, pred_KN))\n",
    "    f1_score3_list.append(metrics.f1_score(y_test, pred_KN))\n",
    "    roc_3_list.append(metrics.roc_auc_score(y_test, y_score_3))\n",
    "    \n",
    "neigh = KNeighborsClassifier(n_neighbors=acc3_list.index(max(acc3_list))+1)\n",
    "neigh.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. [Decision Tree](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "acc4=[]\n",
    "max_depth = []\n",
    "for i in range(2, 10):\n",
    "    clf_DT = DecisionTreeClassifier(random_state=0, max_depth = i)\n",
    "    clf_DT.fit(X_train, y_train)\n",
    "    pred_DT = clf_DT.predict(X_test)\n",
    "    pred_DT = average(pred_DT)\n",
    "    acc4.append(accuracy_score(pred_DT, y_test))\n",
    "    max_depth.append(i)\n",
    "\n",
    "best_depth_4 = max_depth[acc4.index(max(acc4))]\n",
    "\n",
    "clf_DT = DecisionTreeClassifier(random_state=0, max_depth = best_depth_4)\n",
    "clf_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [Random Forest](https://www.javatpoint.com/machine-learning-random-forest-algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc5=[]\n",
    "max_depth = []\n",
    "for i in range(2, 10):\n",
    "    clf_RF = RandomForestClassifier(max_depth=i)\n",
    "    clf_RF.fit(X_train, y_train) \n",
    "    pred_RF = clf_RF.predict(X_test)\n",
    "    pred_RF = average(pred_RF)\n",
    "    acc5.append(accuracy_score(pred_RF, y_test))\n",
    "    max_depth.append(i)\n",
    "\n",
    "best_depth_5 = max_depth[acc5.index(max(acc5))]\n",
    "\n",
    "clf_RF = RandomForestClassifier(max_depth=best_depth_5)\n",
    "clf_RF.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. [XGBoosting](https://towardsdatascience.com/xgboost-theory-and-practice-fb8912930ad6#:~:text=XGBoost%20stands%20for%20eXtreme%20Gradient,power%20and%20ease%20of%20use.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_XGB = XGBClassifier()\n",
    "clf_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. [MLP](https://towardsdatascience.com/deep-neural-multilayer-perceptron-mlp-with-scikit-learn-2698e77155e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/Dayan/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "F1_score_list = []\n",
    "acc7_list = []\n",
    "roc_list = []\n",
    "mlp = []\n",
    "\n",
    "hidden_units = [10,20,30,40,50,60,70]\n",
    "optimizer = ['sgd','adam','lbfgs']\n",
    "activation = ['logistic','tanh','relu']\n",
    "\n",
    "for j in activation:\n",
    "    for i in optimizer:\n",
    "        for k in hidden_units:\n",
    "            clf_MLP = MLPClassifier(hidden_layer_sizes= k, activation =  j, solver= i)\n",
    "            clf_MLP.fit(X_train, y_train)\n",
    "            pred_MLP = clf_MLP.predict(X_test)\n",
    "            pred_MLP = average(pred_MLP)\n",
    "            y_score_7 = clf_MLP.predict_proba(X_test)[:,1]\n",
    "            acc7_list.append(accuracy_score(y_test,pred_MLP))\n",
    "            roc_list.append(metrics.roc_auc_score(y_test, y_score_7))\n",
    "            F1_score_list.append(metrics.f1_score(y_test, pred_MLP))\n",
    "            mlp.append([j,i,k])\n",
    "\n",
    "min_index = acc7_list.index(max(acc7_list))\n",
    "\n",
    "clf_MLP = MLPClassifier(hidden_layer_sizes= mlp[min_index][2], activation =  mlp[min_index][0], solver= mlp[min_index][1])\n",
    "clf_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. [CNN](https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.6857 - accuracy: 0.5514 - val_loss: 0.6935 - val_accuracy: 0.5617\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.5978 - val_loss: 0.6922 - val_accuracy: 0.5813\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6613 - accuracy: 0.6081 - val_loss: 0.6914 - val_accuracy: 0.5808\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6536 - accuracy: 0.6177 - val_loss: 0.6916 - val_accuracy: 0.5458\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6501 - accuracy: 0.6327 - val_loss: 0.6912 - val_accuracy: 0.5421\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6511 - accuracy: 0.6329 - val_loss: 0.6896 - val_accuracy: 0.5475\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6469 - accuracy: 0.6349 - val_loss: 0.6877 - val_accuracy: 0.5508\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6408 - accuracy: 0.6439 - val_loss: 0.6866 - val_accuracy: 0.5408\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6404 - accuracy: 0.6433 - val_loss: 0.6849 - val_accuracy: 0.5321\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6348 - accuracy: 0.6440 - val_loss: 0.6830 - val_accuracy: 0.5321\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6351 - accuracy: 0.6503 - val_loss: 0.6799 - val_accuracy: 0.5396\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6365 - accuracy: 0.6370 - val_loss: 0.6777 - val_accuracy: 0.5412\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6350 - accuracy: 0.6396 - val_loss: 0.6759 - val_accuracy: 0.5417\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6314 - accuracy: 0.6498 - val_loss: 0.6753 - val_accuracy: 0.5337\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.6584 - val_loss: 0.6760 - val_accuracy: 0.5321\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6263 - accuracy: 0.6528 - val_loss: 0.6766 - val_accuracy: 0.5304\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6244 - accuracy: 0.6572 - val_loss: 0.6765 - val_accuracy: 0.5288\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6208 - accuracy: 0.6563 - val_loss: 0.6760 - val_accuracy: 0.5267\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.6613 - val_loss: 0.6772 - val_accuracy: 0.5271\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6205 - accuracy: 0.6518 - val_loss: 0.6783 - val_accuracy: 0.5221\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6181 - accuracy: 0.6590 - val_loss: 0.6770 - val_accuracy: 0.5250\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6153 - accuracy: 0.6612 - val_loss: 0.6785 - val_accuracy: 0.5208\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6169 - accuracy: 0.6610 - val_loss: 0.6762 - val_accuracy: 0.5283\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6132 - accuracy: 0.6738 - val_loss: 0.6750 - val_accuracy: 0.5292\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6107 - accuracy: 0.6761 - val_loss: 0.6735 - val_accuracy: 0.5346\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6095 - accuracy: 0.6726 - val_loss: 0.6728 - val_accuracy: 0.5342\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6134 - accuracy: 0.6693 - val_loss: 0.6709 - val_accuracy: 0.5425\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6077 - accuracy: 0.6761 - val_loss: 0.6704 - val_accuracy: 0.5442\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.6671 - val_loss: 0.6675 - val_accuracy: 0.5579\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6082 - accuracy: 0.6695 - val_loss: 0.6672 - val_accuracy: 0.5638\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.6731 - val_loss: 0.6668 - val_accuracy: 0.5604\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.6784 - val_loss: 0.6657 - val_accuracy: 0.5667\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6178 - accuracy: 0.6619 - val_loss: 0.6652 - val_accuracy: 0.5671\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6100 - accuracy: 0.6642 - val_loss: 0.6643 - val_accuracy: 0.5683\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6070 - accuracy: 0.6810 - val_loss: 0.6637 - val_accuracy: 0.5696\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.6744 - val_loss: 0.6618 - val_accuracy: 0.5746\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6014 - accuracy: 0.6841 - val_loss: 0.6614 - val_accuracy: 0.5746\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6806 - val_loss: 0.6611 - val_accuracy: 0.5767\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6038 - accuracy: 0.6778 - val_loss: 0.6593 - val_accuracy: 0.5775\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.6773 - val_loss: 0.6588 - val_accuracy: 0.5796\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.6777 - val_loss: 0.6578 - val_accuracy: 0.5829\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6930 - val_loss: 0.6584 - val_accuracy: 0.5821\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6879 - val_loss: 0.6577 - val_accuracy: 0.5858\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6024 - accuracy: 0.6820 - val_loss: 0.6555 - val_accuracy: 0.5904\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5991 - accuracy: 0.6900 - val_loss: 0.6541 - val_accuracy: 0.5938\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6885 - val_loss: 0.6553 - val_accuracy: 0.5925\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6928 - val_loss: 0.6537 - val_accuracy: 0.5983\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.6789 - val_loss: 0.6527 - val_accuracy: 0.6012\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6851 - val_loss: 0.6537 - val_accuracy: 0.5987\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6994 - val_loss: 0.6535 - val_accuracy: 0.6008\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6886 - val_loss: 0.6526 - val_accuracy: 0.6029\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5899 - accuracy: 0.6951 - val_loss: 0.6523 - val_accuracy: 0.6046\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.6864 - val_loss: 0.6528 - val_accuracy: 0.6046\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5930 - accuracy: 0.6871 - val_loss: 0.6510 - val_accuracy: 0.6075\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6817 - val_loss: 0.6514 - val_accuracy: 0.6083\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6974 - val_loss: 0.6502 - val_accuracy: 0.6117\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5933 - accuracy: 0.6949 - val_loss: 0.6497 - val_accuracy: 0.6137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6903 - val_loss: 0.6500 - val_accuracy: 0.6125\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5943 - accuracy: 0.6898 - val_loss: 0.6491 - val_accuracy: 0.6162\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6817 - val_loss: 0.6484 - val_accuracy: 0.6192\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.6977 - val_loss: 0.6474 - val_accuracy: 0.6225\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.7009 - val_loss: 0.6461 - val_accuracy: 0.6258\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5900 - accuracy: 0.6955 - val_loss: 0.6470 - val_accuracy: 0.6225\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5823 - accuracy: 0.7074 - val_loss: 0.6470 - val_accuracy: 0.6233\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6923 - val_loss: 0.6461 - val_accuracy: 0.6279\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5906 - accuracy: 0.6964 - val_loss: 0.6457 - val_accuracy: 0.6288\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.6928 - val_loss: 0.6461 - val_accuracy: 0.6308\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5867 - accuracy: 0.6987 - val_loss: 0.6460 - val_accuracy: 0.6325\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7029 - val_loss: 0.6455 - val_accuracy: 0.6354\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.7042 - val_loss: 0.6443 - val_accuracy: 0.6350\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5846 - accuracy: 0.6998 - val_loss: 0.6434 - val_accuracy: 0.6363\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5869 - accuracy: 0.6915 - val_loss: 0.6433 - val_accuracy: 0.6392\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.7020 - val_loss: 0.6423 - val_accuracy: 0.6429\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5814 - accuracy: 0.7089 - val_loss: 0.6413 - val_accuracy: 0.6467\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5805 - accuracy: 0.7078 - val_loss: 0.6427 - val_accuracy: 0.6433\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5802 - accuracy: 0.7045 - val_loss: 0.6424 - val_accuracy: 0.6463\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6957 - val_loss: 0.6427 - val_accuracy: 0.6471\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5837 - accuracy: 0.7066 - val_loss: 0.6422 - val_accuracy: 0.6471\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5846 - accuracy: 0.7011 - val_loss: 0.6426 - val_accuracy: 0.6471\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5894 - accuracy: 0.6932 - val_loss: 0.6416 - val_accuracy: 0.6513\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5803 - accuracy: 0.7042 - val_loss: 0.6416 - val_accuracy: 0.6513\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.6947 - val_loss: 0.6412 - val_accuracy: 0.6513\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.7164 - val_loss: 0.6405 - val_accuracy: 0.6546\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7125 - val_loss: 0.6407 - val_accuracy: 0.6546\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5828 - accuracy: 0.7071 - val_loss: 0.6399 - val_accuracy: 0.6562\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7166 - val_loss: 0.6392 - val_accuracy: 0.6579\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5779 - accuracy: 0.7067 - val_loss: 0.6393 - val_accuracy: 0.6575\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7044 - val_loss: 0.6393 - val_accuracy: 0.6567\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5751 - accuracy: 0.7055 - val_loss: 0.6388 - val_accuracy: 0.6575\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5747 - accuracy: 0.7052 - val_loss: 0.6395 - val_accuracy: 0.6567\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5782 - accuracy: 0.7101 - val_loss: 0.6384 - val_accuracy: 0.6567\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.7038 - val_loss: 0.6379 - val_accuracy: 0.6608\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7097 - val_loss: 0.6380 - val_accuracy: 0.6621\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7170 - val_loss: 0.6378 - val_accuracy: 0.6617\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5797 - accuracy: 0.7047 - val_loss: 0.6377 - val_accuracy: 0.6612\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5786 - accuracy: 0.7127 - val_loss: 0.6370 - val_accuracy: 0.6646\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5772 - accuracy: 0.7092 - val_loss: 0.6374 - val_accuracy: 0.6629\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7043 - val_loss: 0.6362 - val_accuracy: 0.6654\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7114 - val_loss: 0.6376 - val_accuracy: 0.6642\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.5803 - accuracy: 0.7095 - val_loss: 0.6382 - val_accuracy: 0.6617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbd2cba550>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_shaped = np.expand_dims(X_train, axis=2)\n",
    "X_train_shaped.shape\n",
    "X_test_shaped = np.expand_dims(X_test, axis=2)\n",
    "X_test_shaped.shape\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Dropout\n",
    "## Create Model ##\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation = 'relu', input_shape = (8,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "## Compile Model ##\n",
    "optimizer = Adam(lr=0.00001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "## Train Model and Check Validation Accuracy ##\n",
    "model.fit(X_train_shaped, y_train, validation_data = (X_test_shaped,y_test), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables for further use\n",
    "mean = pd.DataFrame() \n",
    "std = pd.DataFrame()\n",
    "ten_consecutive_predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vtx54-AqGc9"
   },
   "outputs": [],
   "source": [
    "def model_with_result(landmarks, selected_algorithm):\n",
    "    \n",
    "    features = pd.DataFrame(columns=[\"EAR\",\"MAR\",\"PUC\",\"MOE\"])\n",
    "\n",
    "    eye = landmarks[36:48]\n",
    "    mouth = landmarks[48:68]\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    cir = pupil_circularity(eye)\n",
    "    mouth_eye = mouth_over_eye(eye, mouth)\n",
    "\n",
    "    df = features.append({\"EAR\":ear,\"MAR\": mar,\"PUC\": cir,\"MOE\": mouth_eye},ignore_index=True)\n",
    "    \n",
    "    global mean\n",
    "    global std\n",
    "    global ten_consecutive_predictions\n",
    "    \n",
    "    df[\"EAR_N\"] = (df[\"EAR\"]- mean[\"EAR\"])/ std[\"EAR\"]\n",
    "    df[\"MAR_N\"] = (df[\"MAR\"]- mean[\"MAR\"])/ std[\"MAR\"]\n",
    "    df[\"PUC_N\"] = (df[\"PUC\"]- mean[\"PUC\"])/ std[\"PUC\"]\n",
    "    df[\"MOE_N\"] = (df[\"MOE\"]- mean[\"MOE\"])/ std[\"MOE\"]\n",
    "    \n",
    "    if selected_algorithm == '1':\n",
    "        Result = clf_LR.predict(df)\n",
    "    elif selected_algorithm == '2':\n",
    "        Result = clf_NB.predict(df)\n",
    "    elif selected_algorithm == '3':\n",
    "        Result = neigh.predict(df)\n",
    "    elif selected_algorithm == '4':\n",
    "        Result = clf_DT.predict(df)\n",
    "    elif selected_algorithm == '5':\n",
    "        Result = clf_RF.predict(df)\n",
    "    elif selected_algorithm == '6':\n",
    "        Result = clf_XGB.predict(df)\n",
    "    elif selected_algorithm == '7':\n",
    "        Result = clf_MLP.predict(df)\n",
    "    elif selected_algorithm == '8':\n",
    "        np_array = np.expand_dims(df, axis=2)\n",
    "        Result = model.predict_classes(np_array)\n",
    "    \n",
    "    ten_consecutive_predictions.append(Result)\n",
    "        \n",
    "    if len(ten_consecutive_predictions) == 10:  \n",
    "        average = sum(ten_consecutive_predictions) / 10 # each frame's 2nd previous, previous and ifself's label average will be used for new label \n",
    "        \n",
    "        if average >= 0.5:\n",
    "            Result = 1\n",
    "        else:\n",
    "            Result = 0\n",
    "                \n",
    "        ten_consecutive_predictions = ten_consecutive_predictions[-9:]\n",
    "        \n",
    "    if Result == 1:\n",
    "        Result_String = \"Drowsy\"\n",
    "    elif Result == 0:\n",
    "        Result_String = \"Alert\"\n",
    "    \n",
    "    return Result_String, df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. https://www.quora.com/In-image-processing-applications-why-do-we-convert-from-RGB-to-Grayscale\n",
    "# 2. https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/\n",
    "\n",
    "# 3. <img src=\"https://www.pyimagesearch.com/wp-content/uploads/2017/04/facial_landmarks_68markup-1024x825.jpg\" style=\"width: 40vw; height: 50vh\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-hbYdBYqGdK"
   },
   "outputs": [],
   "source": [
    "def live_drowsiness_prediction():\n",
    "    cap = cv2.VideoCapture(0) # VideoCapture(0) function to capture the feed of the webcam here 0 \n",
    "                              # indicates the default value of webcam.\n",
    "    data = []\n",
    "    result = []\n",
    "    selected_algorithm = ''\n",
    "    str_headline = 'Please select an algorithm to predict drowsiness'\n",
    "    previous_time = time.time()\n",
    "    millisecs = 0\n",
    "    Result_String = 'Alert'\n",
    "    \n",
    "    while True:\n",
    "        # Getting out image by webcam \n",
    "        _, image = cap.read()\n",
    "\n",
    "        # Converting the image to gray scale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "        \n",
    "        # waitKey(0) shows a still image until a key is press, waitKey(1) shows a frame for at least 1 ms only\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == ord('1'):\n",
    "            selected_algorithm = '1'\n",
    "            str_headline = 'Drowsiness Detection using Logistic Regression'\n",
    "        elif k == ord('2'):\n",
    "            selected_algorithm = '2'\n",
    "            str_headline = 'Drowsiness Detection using Naive Bayes'\n",
    "        elif k == ord('3'):\n",
    "            selected_algorithm = '3'\n",
    "            str_headline = 'Drowsiness Detection using KNN'\n",
    "        elif k == ord('4'):\n",
    "            selected_algorithm = '4'\n",
    "            str_headline = 'Drowsiness Detection using Decision Tree'\n",
    "        elif k == ord('5'):\n",
    "            selected_algorithm = '5'\n",
    "            str_headline = 'Drowsiness Detection using Random Forest'\n",
    "        elif k == ord('6'):\n",
    "            selected_algorithm = '6'\n",
    "            str_headline = 'Drowsiness Detection using XGBoosting'\n",
    "        elif k == ord('7'):\n",
    "            selected_algorithm = '7'\n",
    "            str_headline = 'Drowsiness Detection using MLP'\n",
    "        elif k == ord('8'):\n",
    "            selected_algorithm = '8'\n",
    "            str_headline = 'Drowsiness Detection using CNN'\n",
    "\n",
    "        cv2.putText(image, str_headline, TopMiddleCornerOfText, font, fontScale, fontColor,lineType)\n",
    "        \n",
    "        cv2.putText(image, \"Press '1' to select Logistic Regression\", (10, 20), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '2' to select Naive Bayes\", (10, 40), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '3' to select KNN\", (10, 60), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '4' to select Decision Tree\", (10, 80), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '5' to select Random Forest\", (10, 100), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '6' to select XGBoosting\", (10, 120), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '7' to select MLP\", (10, 140), font, fontScale, fontColor,lineType)\n",
    "        cv2.putText(image, \"Press '8' to select CNN\", (10, 160), font, fontScale, fontColor,lineType)\n",
    "        \n",
    "        cv2.putText(image,\"If you want to close the program press 'Esc'\", bottomRightCornerOfText, font, fontScale, fontColor,lineType)\n",
    "        \n",
    "        \n",
    "        if selected_algorithm != '':\n",
    "            # Get faces into webcam's image\n",
    "            rects = detector(image, 0) # second parameter is the number of image pyramid layers to apply \n",
    "                                       # when upscaling the image prior to applying the detector\n",
    "            \n",
    "            # For each detected face, find the landmark.\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                # Make the prediction and transfom it to numpy array\n",
    "                shape = predictor(gray, rect) # giving us the fancial landmarks of 68 (x, y)-coordinates that \n",
    "                                              # map to the specific facial features in the image. function \n",
    "                                              # returns dlib object\n",
    "                shape = face_utils.shape_to_np(shape) # converts the dlib shape object to a NumPy array with shape (68, 2)\n",
    "                \n",
    "                \n",
    "                if Result_String == 'Drowsy':\n",
    "                    cv2.putText(image,Result_String, bottomLeftCornerOfText, font, 1, (0, 0, 255),lineType)\n",
    "                else:\n",
    "                    cv2.putText(image,Result_String, bottomLeftCornerOfText, font, 1, (0, 255, 0),lineType)\n",
    "                \n",
    "                current_time = time.time()\n",
    "                \n",
    "                if current_time - previous_time >= 0.3:\n",
    "                        \n",
    "#                         print(millisecs, end='\\r')                          \n",
    "                        previous_time = current_time\n",
    "                        millisecs += 1\n",
    "                        Result_String, features = model_with_result(shape, selected_algorithm)\n",
    "                        \n",
    "                        data.append (features)\n",
    "                        result.append(Result_String)\n",
    "                        \n",
    "                        pygame.init()\n",
    "                        if Result_String == 'Drowsy':\n",
    "                            pygame.mixer.music.load('alarm.wav')\n",
    "                            pygame.mixer.music.play()\n",
    "        #                     time.sleep(5)\n",
    "                        else:\n",
    "                            pygame.mixer.music.stop()\n",
    "                     \n",
    "\n",
    "                # Draw on our image, all the finded cordinate points (x,y) \n",
    "                for (x, y) in shape:\n",
    "                    cv2.circle(image, (x, y), 2, (0, 255, 0), -1) # cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "                                                                  # loop over the detected facial landmarks and \n",
    "                                                                  # draw each of them individually.\n",
    "\n",
    "            k = cv2.waitKey(1)\n",
    "            if k == 27:   # ASCII for esc\n",
    "                break\n",
    "        \n",
    "        # Show the image\n",
    "        cv2.imshow(\"Drowsiness and Lethargy Detector\", image)\n",
    "\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    \n",
    "    return data, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtZJFa5qqGdE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (10,600)\n",
    "bottomRightCornerOfText = (800, 700)\n",
    "TopMiddleCornerOfText = (500, 15)\n",
    "fontScale              = 0.6\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "\n",
    "# wait for perfect position to start calibration\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Getting out image by webcam \n",
    "    _, image = cap.read() # web\n",
    "    cv2.putText(image,\"Be in proper position and press 's' to start calibration\", (750, 700), font, fontScale, fontColor,lineType)\n",
    "     # Show the image\n",
    "    cv2.imshow(\"Drowsiness and Lethargy Detector\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break\n",
    "# end of waiting \n",
    "\n",
    "#Run Calibration\n",
    "data = []\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "previous_time = time.time()\n",
    "secs = 0\n",
    "while secs <= 30:  # Calibrate for 30 secs\n",
    "\n",
    "    # Getting out image by webcam \n",
    "    _, image = cap.read() # web cam image three dimensional nparray size = 1280 * 720 * 3 \n",
    "    \n",
    "    cv2.putText(image, 'Counting 30 seconds for calibration: ' + str(secs), bottomRightCornerOfText, font, fontScale, fontColor,lineType)\n",
    "    \n",
    "    # Converting the image to gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # gray is two dimensional nparray size = 720, 1280\n",
    "    # Get faces into webcam's image\n",
    "    rects = detector(image, 0)  # second parameter is the number of image pyramid layers to apply \n",
    "                                # when upscaling the image prior to applying the detector\n",
    "\n",
    "    # For each detected face, find the landmark.\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "        shape = predictor(gray, rect) # giving us the fancial landmarks of 68 (x, y)-coordinates that \n",
    "                                      # map to the specific facial features in the image. function \n",
    "                                      # returns dlib object\n",
    "        shape = face_utils.shape_to_np(shape) # converts the dlib shape object to a NumPy array with shape (68, 2)\n",
    "        data.append(shape)\n",
    "        cv2.putText(image,\"Calibrating...\", bottomLeftCornerOfText, font, 1, fontColor,lineType)\n",
    "        \n",
    "          # Draw on our image, all the finded cordinate points (x,y) \n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1) # cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "                                                          # loop over the detected facial landmarks and \n",
    "                                                          # draw each of them individually.\n",
    "\n",
    "    # Show the image\n",
    "    cv2.imshow(\"Drowsiness and Lethargy Detector\", image)\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "    # current time\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Update and keep track of Countdown\n",
    "    # if time elapsed is one second\n",
    "    # than decrese the counter\n",
    "    if current_time - previous_time >= 1:\n",
    "        previous_time = current_time\n",
    "        secs += 1\n",
    "\n",
    "features_test = []\n",
    "for d in data:\n",
    "    eye = d[36:48]\n",
    "    mouth = d[48: 68]\n",
    "    ear = eye_aspect_ratio(eye)\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    cir = pupil_circularity(eye)\n",
    "    mouth_eye = mouth_over_eye(eye, mouth)\n",
    "    features_test.append([ear, mar, cir, mouth_eye])\n",
    "\n",
    "features = np.array(features_test)\n",
    "\n",
    "df = pd.DataFrame(features,columns=[\"EAR\",\"MAR\",\"PUC\",\"MOE\"])\n",
    "\n",
    "mean = df.mean(axis=0)\n",
    "std = df.std(axis=0)\n",
    "\n",
    "#End of Calibration\n",
    "\n",
    "#Run Demonstration\n",
    "features, result = live_drowsiness_prediction()\n",
    "\n",
    "# print('Result = ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html\n",
    "# 2. https://www.python-course.eu/matplotlib_subplots.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88ctUIfVqGdd",
    "outputId": "423f8e3c-3410-489c-b5ba-8de565c77d9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdbbbd1f490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Results\n",
    "features = np.vstack(features) # Stack arrays in sequence vertically (row wise).\n",
    "\n",
    "y = pd.DataFrame(result,columns=[\"Result\"])\n",
    "\n",
    "y[\"Result\"] = result\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1,       # for each figure 1 row. so total 1 row for total 1 figure\n",
    "                                ncols=1,\n",
    "                                sharex=True,  # True or 'all': x- or y-axis will be shared among all subplots.\n",
    "                                sharey=False,\n",
    "                                figsize=(15, 4))\n",
    "\n",
    "\n",
    "ax1.plot(y[\"Result\"], marker = '.', color = \"Black\", label = \"Person's State\")\n",
    "ax1.set_xlabel('Time (Frames Captured)')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Live Feature Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
